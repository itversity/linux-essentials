{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def html2markdown(html):\n",
    "    # convert html to markdown.\n",
    "    # specification:\n",
    "    # remove all tag exccept tags listed in the cleanbody._repl \n",
    "    # when p/div tags are in the table tag, markdown converter (htmlformatter)\n",
    "    # confuses. so it is removed\n",
    "\n",
    "    # we need following in the header\n",
    "    # import re, html2text\n",
    "    # from bs4 import BeautifulSoup\n",
    "    # CLEANBODY_RE = re.compile(r'<(/?)(.+?)>', re.M)\n",
    "    # htmlformatter = html2text.HTML2Text()\n",
    "    # htmlformatter.ignore_links = True\n",
    "    # htmlformatter.ignore_images = True\n",
    "    # htmlformatter.body_width = 0\n",
    "\n",
    "    def remove_non_table_tags_within_table_tag(html):\n",
    "        def _repl(match):\n",
    "            tag = match.group(2).split(' ')[0].lower()\n",
    "            if tag in ( 'table', 'tr', 'td', 'th'):\n",
    "                  return match.group(0)\n",
    "            return u''\n",
    "\n",
    "        soup =  BeautifulSoup(html, \"lxml\")\n",
    "        for table in soup.find_all('table'):\n",
    "            # find all table element\n",
    "\n",
    "            # convert to string\n",
    "            table_html = str(table)\n",
    "\n",
    "            # remove tags other than  'table', 'tr', 'td', 'th'\n",
    "            clean_table = CLEANBODY_RE.sub(_repl, table_html)\n",
    "\n",
    "            # put back to the original html\n",
    "            table.replace_with(BeautifulSoup(clean_table, \"lxml\"))\n",
    "        return str(soup)\n",
    "\n",
    "    def non_document_tag_remover(match):\n",
    "        tag = match.group(2).split(' ')[0].lower()\n",
    "        if tag in ( 'iframe', 'pre', 'br', 'ul', 'li', 'p',  'h1','h2','h3','h4','h5','h6','div','table', 'tr', 'td', 'th'):\n",
    "            return match.group(0)\n",
    "        return u''\n",
    "\n",
    "    #main routine\n",
    "    if html.lower().find('table') > -1:\n",
    "        # clean tags within table tag\n",
    "        html = remove_non_table_tags_within_table_tag(html)\n",
    "\n",
    "    # strip unrelated tags\n",
    "    clean_html = CLEANBODY_RE.sub(non_document_tag_remover, html)\n",
    "\n",
    "    # convert it to markdown\n",
    "    markdown =  htmlformatter.handle(clean_html)\n",
    "\n",
    "    return markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, html2text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, NavigableString, Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEANBODY_RE = re.compile(r'<(/?)(.+?)>', re.M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "htmlformatter = html2text.HTML2Text()\n",
    "htmlformatter.ignore_images = True\n",
    "htmlformatter.body_width = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_content = open('content.html').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_soup = BeautifulSoup(html_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for script in html_soup([\"script\", \"style\"]):\n",
    "    script.decompose()    # rip it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'linux_commands_–_system_details_and_standard_directories_–_kaizen'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_soup. \\\n",
    "    find(name='title'). \\\n",
    "    get_text(). \\\n",
    "    lower(). \\\n",
    "    replace('(', ''). \\\n",
    "    replace(')', ''). \\\n",
    "    replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_text = html_soup.find(attrs={'class': 'ld-tab-content'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_list = []\n",
    "for header in html_text.find_all('h2'):\n",
    "    nextNode = header\n",
    "    header_text = header.get_text()\n",
    "    html_ele = str(nextNode)\n",
    "    while True:\n",
    "        nextNode = nextNode.nextSibling\n",
    "        if nextNode is None:\n",
    "            break\n",
    "        if isinstance(nextNode, Tag):\n",
    "            if nextNode.name == \"h2\":\n",
    "                break\n",
    "        html_ele += str(nextNode)\n",
    "    html_list.append((header_text, html_ele))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_list = []\n",
    "for html_ele in html_list:\n",
    "    md = html2markdown(html_ele[1])\n",
    "    md_list.append((html_ele[0], md))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = open('template.ipynb').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, md_ele in enumerate(md_list):\n",
    "    notebook = json.loads(content)\n",
    "    notebook_file_name = f'{str(idx + 1).zfill(2)}_{md_ele[0].lower().replace(\" \", \"_\")}.ipynb'\n",
    "    notebook_file = open(notebook_file_name, 'w')\n",
    "    notebook['cells'][0]['source'] = md_ele[1]\n",
    "    json.dump(notebook, notebook_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fPQPzLABrT4\n",
      "vXNe5VJlkec\n",
      "l9mJNLqUm7w\n",
      "hytP_X_gFLs\n",
      "vS4Rgo2SIvo\n",
      "ZFNkEpSX2dU\n",
      "K6nEUncFUzI\n",
      "cVH9lraIMTI\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup, NavigableString, Tag\n",
    "html_content = open('content.html').read()\n",
    "html_soup = BeautifulSoup(html_content)\n",
    "for iframe in html_soup.find_all(name='iframe'):\n",
    "    print(iframe['src'].split('/')[-1].split('?')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
